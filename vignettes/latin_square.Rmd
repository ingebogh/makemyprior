---
title: "Latin square experiment"
author: Ingeborg Gullikstad Hem (ingeborg.hem@ntnu.no)
output: 
  rmarkdown::html_vignette:
    toc: true
bibliography: references.bib
vignette: >
  %\VignetteIndexEntry{latin_square}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: 72
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(rmarkdown.html_vignette.check_title = FALSE)
```

```{r setup}
library(makemyprior)
```

### Model

We consider a latin square experiment, with a 9x9 latin square design,
following the procedure of @fuglstad2020. We assume we have the
following model: $$
  y_{i,j} = \alpha + \beta \cdot k[i,j] + a_i + b_j + c_{k[i,j]} + \varepsilon_{i,j}, \quad i,j = 1, \dots, 9,
$$ where

-   $a$ is an intercept with $\alpha \sim N(0, 1000^2)$,
-   $b \cdot k[i,j]$ is a linear effect of treatment and
    $\beta \sim N(0, 1000^2)$,
-   $\mathbf{a} = (a_1, \dots, a_9)^\top \sim N_9(\mathbf{0}, \sigma_{a}^2 \mathbf{I}_9)$
    is a row effect,
-   $\mathbf{b} = (b_1, \dots, b_9)^\top \sim N_9(\mathbf{0}, \sigma_{b}^2 \mathbf{I}_9)$
    is a column effect,
-   $\mathbf{\varepsilon} = (\varepsilon_{1,1},\varepsilon_{1,2} \dots, \varepsilon_{9,9})^\top \sim N_{81}(\mathbf{0}, \sigma_{\varepsilon}^2 \mathbf{I}_{81})$
    is residual noise,
-   the treatment effect consists of:
    -   a smooth signal
        $\mathbf{c}^{(1)} = (c_1^{(1)}, \dots, c_9^{(1)}) \sim (\mathbf{0}, \sigma_{c^{(1)}}^2 \mathbf{Q}_{\mathrm{RW2}}^{-1})$
        where $\sigma_{c^{(1)}}^2$ is the variance and
        $\mathbf{Q}_{\mathrm{RW2}}^{-1}$ is the covariance matrix
        describing the intrinsic second-order random walk, and
    -   random noise
        $\mathbf{c}^{(2)} = (c_1^{(2)}, \dots, c_9^{(2)}) \sim N_9(\mathbf{0}, \sigma_{c^{(2)}}^2 \mathbf{I}_9)$.

We remove implicit intercept and linear effect by requiring
$\sum_{i=1}^9 c_i^{(1)} = 0$ and $\sum_{i=1}^9 i c_i^{(1)} = 0$.

The model is specified as:

```{r}
formula <- y ~ lin + mc(row) + mc(col) + mc(iid, constr = TRUE) +
  mc(rw2, model = "rw2", constr = TRUE, lin_constr = TRUE)
```

We use the dataset `latin_square` in `makemyprior`, and present three
priors. We do not carry out inference, as it takes time and will slow
down the compilation of the vignettes by a lot, but include code so the
user can carry out the inference themselves.

### Prior 1 {#prior1}

We want to avoid overfitting of the model, and use a prior with
shrinkage towards the residuals in the top split with median of $0.25$.
We do not have any preference for the attribution of the row, column and
treatment effects, and use an ignorant Dirichlet prior for the middle
split. In the bottom split we again we want to avoid overfitting, and
use a prior with shrinkage towards the unstructured treatment effect and
a median corresponding to 75% unstructured treatment effect. We do not
want to say anything about the scale of the total variance, and use the
default Jeffreys' prior.

```{r}
prior1 <- make_prior(
  formula, latin_data,
  prior = list(tree = "s1 = (iid, rw2); s2 = (row, col, s1); s3 = (s2, eps)",
               w = list(s1 = list(prior = "pc1", param = 0.75),
                        s2 = list(prior = "dirichlet"),
                        s3 = list(prior = "pc0", param = 0.25))))

prior1

```

```{r, fig.width = 6, fig.height = 3}
plot_prior(prior1) # or plot(prior)
```

```{r, fig.width = 3, fig.height = 3}
plot_tree_structure(prior1)
```

Inference can be carried out by running:

```{r, eval = FALSE}
posterior1 <- inference_stan(prior1, iter = 15000, warmup = 5000,
                            seed = 1, init = "0", chains = 1)
plot_posterior_stan(posterior1, param = "prior", prior = TRUE)

```

For inference with INLA we need to include the linear constraint in a
different way:

```{r, eval = FALSE}
formula_inla <- y ~ lin + mc(row) + mc(col) + mc(iid, constr = TRUE) +
  mc(rw2, model = "rw2", constr = TRUE, extraconstr = list(A = matrix(1:9, 1, 9), e = matrix(0, 1, 1)))
prior1_inla <- make_prior(
  formula_inla, latin_data,
  prior = list(tree = "s1 = (iid, rw2); s2 = (row, col, s1); s3 = (s2, eps)",
               w = list(s1 = list(prior = "pc1", param = 0.75),
                        s2 = list(prior = "dirichlet"),
                        s3 = list(prior = "pc0", param = 0.25))))

posterior1_inla <- inference_inla(prior1_inla)
plot_posterior_stdev(posterior1_inla)

```

### Prior 2 {#prior2}

We can imagine we do not not want to include the residual effect in the
tree with the row, column and treatment effects, and assume we have
prior knowledge that the latent variance
$\sigma_{a}^2 + \sigma_{b}^2 + \sigma_{c^{(1)}}^2 + \sigma_{c^{(2)}}^2$
is not not larger than $0.25$, and use a PC prior for variance that
fulfills $\text{P}(\text{total st.dev.} > sqrt(0.2)) = 0.05$. We assume
we have knowledge saying that the same is true for the residual
variance. We assume the latent variance is distributed in the same way
as in [Prior 1](#prior1).

```{r}
prior2 <- make_prior(
  formula, latin_data,
  prior = list(tree = "s1 = (iid, rw2); s2 = (row, col, s1); (eps)",
               w = list(s1 = list(prior = "pc1", param = 0.75),
                        s2 = list(prior = "dirichlet")),
               V = list(s2 = list(prior = "pc", param = c(sqrt(0.2), 0.05)),
                        eps = list(prior = "pc", param = c(sqrt(0.2), 0.05)))))

prior2

```

```{r, fig.width = 6, fig.height = 3}
plot_prior(prior2) # or plot(prior2)
```

```{r, fig.width = 3, fig.height = 3}
plot_tree_structure(prior2)
```

Inference can be carried out by running:

```{r, eval = FALSE}
posterior2 <- inference_stan(prior2, iter = 15000, warmup = 5000,
                            seed = 1, init = "0", chains = 1)
plot_posterior_stan(posterior2)

```

### Prior 3

In the last prior, we use component-wise priors on row, column,
treatment and residual variance, but use a PC prior with shrinkage
towards the unstructured treatment effect to avoid overfitting. We use a
strong prior, and say that that the all variances are not much larger
than $0.1$.

```{r}
prior3 <- make_prior(
  formula, latin_data,
  prior = list(tree = "(row); (col); (iid); (rw2); (eps)",
               V = list(
                 row = list(prior = "pc", param = c(sqrt(0.1), 0.05)),
                 col = list(prior = "pc", param = c(sqrt(0.1), 0.05)),
                 iid = list(prior = "pc", param = c(sqrt(0.1), 0.05)),
                 rw2 = list(prior = "pc", param = c(sqrt(0.1), 0.05)),
                 eps = list(prior = "pc", param = c(sqrt(0.1), 0.05))
               )))

prior3

```

```{r, fig.width = 6, fig.height = 3}
plot_prior(prior3) # or plot(prior3)
```

```{r, fig.width = 3, fig.height = 3}
plot_tree_structure(prior3)
```

Inference can be carried out by running:

```{r, eval = FALSE}
posterior3 <- inference_stan(prior3, iter = 15000, warmup = 5000,
                            seed = 1, init = "0", chains = 1)
plot_posterior_stan(posterior3)

```

```{r}
sessionInfo()
```

### References
